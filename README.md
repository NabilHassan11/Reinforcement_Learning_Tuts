# ğŸ¤– Reinforcement Learning Tutorials:ğŸ§ 

# 1ï¸âƒ£ MDP & Dynamic Programming Tutorial

Welcome to the **MDP_DP** folder! This section of the repository focuses on **Markov Decision Processes (MDPs)** **Bellman Optimality Equations** and **Dynamic Programming (DP)** techniques in Reinforcement Learning.

## ğŸ­ Warehouse Maintenance Optimization with MDPs & Dynamic Programming âš™ï¸

![MDP Diagram](![image](https://github.com/user-attachments/assets/04281750-c46e-4c50-93a4-f2284c632e57)
)
) *Visualization of the warehouse maintenance MDP*

### ğŸ” Problem Statement
**Task:** Optimize maintenance strategies for robotic systems in a warehouse using Reinforcement Learning.  
**Challenge:** Prevent robotic system failures while minimizing downtime through optimal maintenance scheduling.  
**Goal:** Find the policy that maximizes long-term rewards using **Markov Decision Processes (MDPs)** and **Dynamic Programming**.

---

### ğŸ“¦ Environment Specification (MDP)

#### ğŸ§© States
| State | Symbol | Description | 
|-------|--------|-------------|
| Operational | ğŸŸ¢ **O** | Robot functioning normally |
| Needs Maintenance | ğŸŸ¡ **NM** | Early wear signs but operational |
| Maintenance | ğŸ”µ **M** | Undergoing scheduled maintenance | 
| Broken | ğŸ”´ **B** | Critical failure state |

#### ğŸ® Actions
| Action | Symbol | Description |
|--------|--------|-------------|
| Perform Maintenance | PM | Proactive maintenance |
| Continue Operation | CO | No intervention |
| Schedule Maintenance | SM | Plan future maintenance |
| Repair | R | Fix broken robot |

---

## âš¡ Key Features
```python
# Highlighted code feature: Stochastic transitions
def get_transitions(state, action):
    if state == "NM" and action == "CO":
        # 50% chance breakdown, 50% stay degraded
        return [('B', 0.5), ('NM', 0.5)]
```

ğŸŒ Environment Dynamics
|State	|Action	|Transitions	|Reward|
|-------|-------|---------------|------|
|ğŸŸ¢ O	|CO	|80% stay O, 20% â†’ ğŸŸ¡ NM	|+20 if stays O|
|ğŸŸ¡ NM	|PM	|100% â†’ ğŸ”µ M	|0|
|ğŸ”µ M	|SM	|100% â†’ ğŸŸ¢ O	|+20|
|ğŸ”´ B	|R	|100% â†’ ğŸŸ¢ O	|+20|

â›”Note: The Environment Dynamics is not fully written here you can refer for it from the code 

---

## ğŸ—‚ï¸ Folder Contents
Explore algorithms and implementations for solving MDPs using DP methods:
- **Policy Iteration** ğŸ”„
- **Value Iteration** âš¡
- **Policy Evaluation** ğŸ“Š

### ğŸ“œ Code Files:
| File | Description |
|------|-------------|
| [`policy_iteration.py`](./MDP_DP/policy_iteration.py) | Policy Iteration algorithm implementation |
| [`value_iteration.py`](./MDP_DP/value_iteration.py) | Value Iteration algorithm implementation |
| [`Lecture_3_PolicyEval.py`](./MDP_DP/Lecture_3_PolicyEval.py) | Policy Evaluation demonstration | 

---

## ğŸš€ Quick Start
### Prerequisites
- Python 3.8+
- NumPy (`pip install numpy`)

### Installation
```bash
git clone https://github.com/NabilHassan11/Reinforcement_Learning_Tuts.git
cd Reinforcement_Learning_Tuts/MDP_DP
